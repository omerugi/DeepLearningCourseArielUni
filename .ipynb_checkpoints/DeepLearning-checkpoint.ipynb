{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data and split to train/test , x/y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 24 classes,the class that has the most data is class 17 with 4.713 precents of the data\n",
      "if the data were equals between all classes it needed to be 4.167 precents of the data\n"
     ]
    }
   ],
   "source": [
    "#there are 24 letters but for the order j get an index\n",
    "num_categories=25 \n",
    "\n",
    "# Importing the data - test and train\n",
    "test = pd.read_csv(\"sign_mnist_test.csv\").to_numpy() \n",
    "train = pd.read_csv(\"sign_mnist_train.csv\").to_numpy()\n",
    "\n",
    "# Splitting test into x & y - x = fetures y = labels \n",
    "# Note: we do OneHot on the y to get it as a vector at the size of the categories\n",
    "# then put's 1 where the right label is and zero in the rest\n",
    "y_test=test[:,0]\n",
    "y_test=keras.utils.to_categorical(y_test, num_categories)\n",
    "x_test=test[:,1:]\n",
    "\n",
    "# Splitting data into x & y - x = fetures y = labels\n",
    "# Note: we do OneHot on the y to get it as a vector at the size of the categories\n",
    "# then put's 1 where the right label is and zero in the rest\n",
    "data_y=train[:,0]\n",
    "data_y=keras.utils.to_categorical(data_y, num_categories)\n",
    "data_x=train[:,1:]\n",
    "\n",
    "# Getting the number of feturs\n",
    "# Note: in the case of image each pixel and the toal number is n*n\n",
    "lines,features=x_train.shape\n",
    "\n",
    "biggestClass=np.argmax(np.bincount(train[:,0]))\n",
    "precentOfDataOfBiggestClass=np.max(np.bincount(train[:,0]))*100/lines\n",
    "\n",
    "print(\"there are 24 classes,the class that has the most data is class %2d with %.3f precents of the data\"\n",
    "      %(biggestClass,precentOfDataOfBiggestClass))\n",
    "print(\"if the data were equals between all classes it needed to be %.3f precents of the data\" %(100/24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A \"list like\" object that will hold the calculatins as tensors\n",
    "x = tf.placeholder(tf.float32, [None, features])\n",
    "y_ = tf.placeholder(tf.float32, [None, num_categories])\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.zeros([features,num_categories]))\n",
    "b = tf.Variable(tf.zeros([num_categories]))\n",
    "\n",
    "# Define activation function - Softmax \n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# Define the loss function - Cross entropy\n",
    "loss = -tf.reduce_mean(y_*tf.log(y))\n",
    "\n",
    "# Define the update function - Gradient descent\n",
    "update = tf.train.GradientDescentOptimizer(0.0001).minimize(loss)\n",
    "\n",
    "# Define accuracy - Percentage of predictions did we get right\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1),tf.argmax(y_, 1)) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 784)\n",
      "(27455, 25)\n"
     ]
    }
   ],
   "source": [
    "print(data_x.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784)\n",
      "(?, 25)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 train_acc: 0.047 test_acc: 0.020\n",
      "epoch: 100 train_acc: 0.365 test_acc: 0.296\n",
      "epoch: 200 train_acc: 0.439 test_acc: 0.413\n",
      "epoch: 300 train_acc: 0.538 test_acc: 0.449\n",
      "epoch: 400 train_acc: 0.581 test_acc: 0.532\n",
      "epoch: 500 train_acc: 0.594 test_acc: 0.543\n",
      "epoch: 600 train_acc: 0.641 test_acc: 0.547\n",
      "epoch: 700 train_acc: 0.668 test_acc: 0.576\n",
      "epoch: 800 train_acc: 0.680 test_acc: 0.584\n",
      "epoch: 900 train_acc: 0.724 test_acc: 0.640\n",
      "epoch: 1000 train_acc: 0.733 test_acc: 0.631\n",
      "epoch: 1100 train_acc: 0.745 test_acc: 0.642\n",
      "epoch: 1200 train_acc: 0.751 test_acc: 0.642\n",
      "epoch: 1300 train_acc: 0.770 test_acc: 0.645\n",
      "epoch: 1400 train_acc: 0.780 test_acc: 0.684\n",
      "epoch: 1500 train_acc: 0.795 test_acc: 0.683\n",
      "epoch: 1600 train_acc: 0.792 test_acc: 0.660\n",
      "epoch: 1700 train_acc: 0.812 test_acc: 0.698\n",
      "epoch: 1800 train_acc: 0.813 test_acc: 0.701\n",
      "epoch: 1900 train_acc: 0.832 test_acc: 0.710\n"
     ]
    }
   ],
   "source": [
    "# Define a session\n",
    "sess = tf.Session()\n",
    "# Init all the vaeiables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(0,2000):\n",
    "    sess.run(update, feed_dict = {x:data_x, y_:data_y}) #BGD \n",
    "    if epoch%100==0: # Every 100 epoches print the current accuracy\n",
    "        feeds_train = {x:data_x, y_:data_y}\n",
    "        feeds_test = {x:x_test, y_:y_test}\n",
    "        train_acc = sess.run(accuracy, feed_dict=feeds_train)\n",
    "        test_acc = sess.run(accuracy, feed_dict=feeds_test)\n",
    "        print (\"epoch: %3d train_acc: %.3f test_acc: %.3f\" % (epoch,train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
